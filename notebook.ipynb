{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_CFG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rusxbags3Ee"
      },
      "source": [
        "# 1 - Comprendre l'outil Google Colab\n",
        "\n",
        "Google Colab permet à n'importe qui d'écrire et d'exécuter du code Python dans le navigateur.\n",
        "\n",
        "Un document s'appelle un notebook ; derrière eux se trouvent des serveurs Linux.\n",
        "\n",
        "Les notebooks peuvent être vus comme une succession de cellules.\n",
        "\n",
        "Et ces cellules peuvent contenir trois types de contenu :\n",
        "\n",
        "- Du code Python\n",
        "- Du code Bash : https://en.wikipedia.org/wiki/Bash_(Unix_shell)\n",
        "- Du texte, mis en forme avec du Markdown : https://www.markdownguide.org/cheat-sheet/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naxHFq-1rJRu"
      },
      "source": [
        "# 2 - Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic0bdX9arRvT"
      },
      "source": [
        "Pour ce TP, vous aurez besoin de Python 3. Vous pouvez vérifier la version de Python du serveur Linux derrière votre notebook en exécutant cette ligne de commande Bash : `!python --version`.\n",
        "\n",
        "\n",
        "*Note : pour que Colab sache qu'il doit exécuter du Bash, ces commandes doivent toujours être précédées d'un point d'exclamation.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQyY7vRGrM3c",
        "outputId": "bd64fc00-3b0c-49ed-c4fa-1173f1ac1e4d"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjWfCDgsrh3m"
      },
      "source": [
        "Installez ensuite ces 3 paquets :\n",
        "\n",
        "1. the Natural Language ToolKit (NLTK) : `pip install nltk`\n",
        "2. Numpy : `pip install numpy`\n",
        "3. Matplotlib : `pip install matplotlib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZojueBWvM3f",
        "outputId": "db573a9f-3b85-4b3f-8ef8-bee912a91efe"
      },
      "source": [
        "!pip install nltk numpy matplotlib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX8E8eqjvd-j"
      },
      "source": [
        "# 3 - Familiarisation avec l’outil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRUEBlWWvjEF"
      },
      "source": [
        "## 3.1 - Python\n",
        "\n",
        "Lorsque vous créez une cellule Python, le notebook attend que vous rédigiez du code et l'exécutiez.\n",
        "\n",
        "Commençons par utiliser Python comme calculette.\n",
        "\n",
        "Pour exécuter une cellule de code, vous devez cliquer sur le bouton Play à gauche de votre cellule.\n",
        "\n",
        "Essayez ci-dessous :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCekj2UWvbsz",
        "outputId": "8ede1cd7-9586-4a39-fbe4-65b8cc40cfe7"
      },
      "source": [
        "4 * 10 + 2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I20xKoSTwiV2"
      },
      "source": [
        "Essayez quelques autres calculs avec les opérateurs `+ - *` et `/` par exemple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMNe85JgwCej",
        "outputId": "77524aa0-fc4d-42a3-a99a-b094d646341b"
      },
      "source": [
        "86 / 2 - 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usKXSMy8wxYJ"
      },
      "source": [
        "Voyons à présent ce qui se passe si l’on tape une expression illogique comme `1 +`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "HmQVQRuAwqyY",
        "outputId": "14e4b6d4-832d-4eaf-fb89-bccb571a6c8d"
      },
      "source": [
        "1 +"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-953e01372b97>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1 +\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefiW50aw4JC"
      },
      "source": [
        "Python renvoie une **erreur de syntaxe** issue du *standard input* (stdin)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1hto5X1xAqp"
      },
      "source": [
        "## 3.2 - NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4d7glCxdPo"
      },
      "source": [
        "Commençons par importer le module NLTK et par télécharger quelques données de test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN9z-L4zwztm",
        "outputId": "ce5c1068-7d6a-46d6-a4e3-de883372a73f"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('book')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /Users/datalody/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ5xXsJNyqo7"
      },
      "source": [
        "Tapez ensuite la commande suivante pour charger\n",
        "les textes (cela prend quelques secondes) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs0xb3WHx7vU",
        "outputId": "d2a06c44-34af-4c84-d769-22ce63988632"
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_vclOxyy1E"
      },
      "source": [
        "Chaque texte porte un nom qui permet de l’invoquer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZqQu1-gx8Kc",
        "outputId": "033b9664-c1fc-431f-c6d8-f6fe78b788f1"
      },
      "source": [
        "text1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzToIUySy0ip",
        "outputId": "cf7ea8ce-f79a-4ba9-b821-1ffa7c8a1261"
      },
      "source": [
        "text2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Sense and Sensibility by Jane Austen 1811>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrCemdazy7jA"
      },
      "source": [
        "Nous pouvons à présent explorer ce corpus, par exemple pour chercher toutes les occurrence de\n",
        "l’adjectif monstrous (monstrueux) en contexte dans Moby Dick :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lOXSTk-y4oH",
        "outputId": "c5abea7c-1726-4a87-cf90-767092c0ccdc"
      },
      "source": [
        "text1.concordance(\"monstrous\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying 11 of 11 matches:\n",
            "ong the former , one was of a most monstrous size . ... This came towards us , \n",
            "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
            "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
            "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
            "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
            "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
            "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
            "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
            "ere to enter upon those still more monstrous stories of them which are to be fo\n",
            "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
            "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h_Hjs9mzJJ8"
      },
      "source": [
        "## 3.3 - Chart parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTPVaiVy9Ff",
        "outputId": "12bdf7c8-fce6-4857-ad5a-52c94fc25fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "# Ne fonctionne qu'en local (hors de Colab)\n",
        "\n",
        "nltk.app.chartparser()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grammar= (\n",
            "('    ', 'S -> NP VP,')\n",
            "('    ', 'VP -> VP PP,')\n",
            "('    ', 'VP -> V NP,')\n",
            "('    ', 'VP -> V,')\n",
            "('    ', 'NP -> Det N,')\n",
            "('    ', 'NP -> NP PP,')\n",
            "('    ', 'PP -> P NP,')\n",
            "('    ', \"NP -> 'John',\")\n",
            "('    ', \"NP -> 'I',\")\n",
            "('    ', \"Det -> 'the',\")\n",
            "('    ', \"Det -> 'my',\")\n",
            "('    ', \"Det -> 'a',\")\n",
            "('    ', \"N -> 'dog',\")\n",
            "('    ', \"N -> 'cookie',\")\n",
            "('    ', \"N -> 'table',\")\n",
            "('    ', \"N -> 'cake',\")\n",
            "('    ', \"N -> 'fork',\")\n",
            "('    ', \"V -> 'ate',\")\n",
            "('    ', \"V -> 'saw',\")\n",
            "('    ', \"P -> 'on',\")\n",
            "('    ', \"P -> 'under',\")\n",
            "('    ', \"P -> 'with',\")\n",
            ")\n",
            "tokens = ['John', 'ate', 'the', 'cake', 'on', 'the', 'table']\n",
            "Calling \"ChartParserApp(grammar, tokens)\"...\n",
            "Error creating Tree View\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2b89c71a42a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ne fonctionne qu'en local (hors de Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchartparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/app/chartparser_app.py\u001b[0m in \u001b[0;36mapp\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2256\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokens = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling \"ChartParserApp(grammar, tokens)\"...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2258\u001b[0;31m     \u001b[0mChartParserApp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/app/chartparser_app.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grammar, tokens, title)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;31m# Create the root window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-q>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "source": [
        "## 3.4 - Construire et tester la grammaire"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSJdtfrnJoet"
      },
      "source": [
        "from nltk import CFG, ChartParser, wordpunct_tokenize\n",
        "\n",
        "\n",
        "def test_grammar(grammar, sentence):\n",
        "    tokens = wordpunct_tokenize(sentence)\n",
        "    cfg_grammar = CFG.fromstring(grammar)\n",
        "    parser = ChartParser(cfg_grammar)\n",
        "    try:\n",
        "        parser_generator = parser.parse(tokens)\n",
        "        tree_list = [t for t in parser_generator]\n",
        "        print(f'{len(tree_list)} parsing found!\\n'.upper())\n",
        "        for i, tree in enumerate(tree_list):\n",
        "            print(f'---- PARSING {i+1} ----')\n",
        "            tree.pprint()\n",
        "            print()\n",
        "    except ValueError as ve:\n",
        "        print(f'no parsing found!\\n'.upper())\n",
        "        print('>', ve)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9LvmFiJoet"
      },
      "source": [
        "grammar = \"\"\"\n",
        "S -> NP VP PP | NP VP\n",
        "NP -> Det N | N\n",
        "VP -> V NP PP | V NP\n",
        "PP -> P NP\n",
        "N -> 'John' | 'cake' | 'table'\n",
        "V -> 'ate'\n",
        "Det -> 'the'\n",
        "P -> 'on' \n",
        "\"\"\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 PARSING FOUND!\n\n---- PARSING 1 ----\n(S\n  (NP (N John))\n  (VP (V ate) (NP (Det the) (N cake)))\n  (PP (P on) (NP (Det the) (N table))))\n\n---- PARSING 2 ----\n(S\n  (NP (N John))\n  (VP\n    (V ate)\n    (NP (Det the) (N cake))\n    (PP (P on) (NP (Det the) (N table)))))\n\n"
          ]
        }
      ],
      "source": [
        "test_grammar(grammar, 'John ate the cake on the table')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}